{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d059262a-1255-40e8-853a-cf04f2907ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# which provides functions to interact with the operating system, including file and directory handling.\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0454dfee-6195-4da4-a003-35a346974ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Images count from Fodlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f84c364-653f-456a-9a52-58f4dc350b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy Folder has 764 Images\n",
      "dandelion Folder has 1052 Images\n",
      "rose Folder has 784 Images\n",
      "sunflower Folder has 733 Images\n",
      "tulip Folder has 984 Images\n",
      "Images Folder has 4317 Images\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "\n",
    "dirs = os.listdir('flowers/') \n",
    "#get a list of all items (files and sub directories) in the 'Images/' directory. In here sub directories only.\n",
    "#dirs = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "#daisy, dandelion, rose, sunflower, tulip are the sub directories inside the flowers directory.\n",
    "\n",
    "#The for loop will iterate over each element(sub directories) in the dirs list. Access to the sub directory one by one\n",
    "for dir in dirs: \n",
    "    \n",
    "    files = list(os.listdir('flowers/'+dir))\n",
    "    #create a list using files inside sub directory\n",
    "    #Ex : if dir value is daisy files =['image1.jpg', 'image2.jpg', 'image3.jpg'................................]\n",
    "    \n",
    "    print( dir +' Folder has '+ str(len(files)) + ' Images')\n",
    "    #daisy Folder has 764 Images\n",
    "    #dandelion Folder has 1052 Images\n",
    "    #rose Folder has 784 Images\n",
    "    #sunflower Folder has 733 Images\n",
    "    #tulip Folder has 984 Images\n",
    "    \n",
    "    count = count + len(files)\n",
    "    \n",
    "print( 'Images Folder has '+ str(count) + ' Images')\n",
    "#Images Folder has 4317 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac67565-38ab-4cd0-8a03-8bd2fa786fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images into Arrays as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316852ca-d96a-4bca-90d4-e6b18617cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'flowers/' #directory where the images are stored\n",
    "img_size = 180        #each image will be resized to 180x180 pixels\n",
    "batch = 32            #number of images to be included in each batch during training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbccd17b-6225-4d65-89e7-b9f6f2b18bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow's utility functions to load image data from a directory, split it into training and validation datasets, and prepare it for use in a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca285ca7-aaaf-4510-8271-4560ce8ab913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 files belonging to 5 classes.\n",
      "Using 3454 files for training.\n",
      "Found 4317 files belonging to 5 classes.\n",
      "Using 863 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Create the training dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory( base_dir,\n",
    "                                                       seed = 123,\n",
    "                                                       validation_split=0.2,\n",
    "                                                       subset = 'training',\n",
    "                                                       batch_size=batch,\n",
    "                                                       image_size=(img_size,img_size))\n",
    "\n",
    "#Create the validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory( base_dir,\n",
    "                                                       seed = 123,\n",
    "                                                       validation_split=0.2,\n",
    "                                                       subset = 'validation',\n",
    "                                                       batch_size=batch,\n",
    "                                                       image_size=(img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e968a-8a93-4d92-a4bf-3c8b744429fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
